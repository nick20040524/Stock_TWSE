# -*- coding: utf-8 -*-
import requests as r
import pandas as pd
from datetime import datetime, date, timedelta
import time
import random
import os

# æŠ“å–æŒ‡å®šè‚¡ç¥¨åœ¨æŒ‡å®šæ™‚é–“ç¯„åœå…§çš„æ­·å²äº¤æ˜“è³‡æ–™ï¼Œä¸¦è½‰æ›ç‚º pandas DataFrame æ ¼å¼
def get_tw_stock_data(start, end, stock_code, listed_date):
    
    # å»ºç«‹æŠ“å–æœƒè©±èˆ‡è¿´åœˆ
    session = r.Session()
    headers = {"User-Agent": "Mozilla/5.0"}
    month_list = pd.date_range(start, end, freq='MS')
    dfs = []

    for month in month_list:

        # é¿å…æŸ¥è©¢æœªä¸Šå¸‚æœˆä»½
        if month < listed_date:
            continue

        # å»ºæ§‹ API URL ä¸¦ç™¼é€è«‹æ±‚
        url = (
            f"https://www.twse.com.tw/exchangeReport/STOCK_DAY"
            f"?response=json&date={month.strftime('%Y%m%d')}&stockNo={stock_code}"
        )

        try:
            res = session.get(url, headers=headers, timeout=10)
            js = res.json()
            if js.get("stat") != "OK":
                continue

            # è§£æ JSON ä¸¦è½‰æ›æ¬„ä½( JSON è½‰ Datafram, æ°‘åœ‹è½‰è¥¿å…ƒ)
            df_m = pd.DataFrame(js.get("data", []), columns=js.get("fields", []))
            df_m["æ—¥æœŸ"] = df_m["æ—¥æœŸ"].str.split("/").apply(
                lambda x: datetime(int(x[0]) + 1911, int(x[1]), int(x[2]))
            )

            # æ•¸å€¼æ¬„ä½æ¸…æ´—èˆ‡è½‰å‹
            for col in ["æˆäº¤è‚¡æ•¸", "æˆäº¤é‡‘é¡", "é–‹ç›¤åƒ¹", "æœ€é«˜åƒ¹", "æœ€ä½åƒ¹", "æ”¶ç›¤åƒ¹", "æ¼²è·Œåƒ¹å·®", "æˆäº¤ç­†æ•¸"]:
                df_m[col] = pd.to_numeric(
                    df_m[col].str.replace("[,X]", "", regex=True), errors='coerce'
                )

            # è³‡æ–™æ•´ä½µ
            df_m.insert(0, "è‚¡ç¥¨ä»£ç¢¼", stock_code)
            dfs.append(df_m)
            time.sleep(random.uniform(0.5, 1.0))

        # éŒ¯èª¤è™•ç†èˆ‡å›å‚³çµæœ
        except Exception as e:
            print(f"âŒ éŒ¯èª¤ï¼š{stock_code} {month.strftime('%Y-%m')} => {e}")
            continue

    # å›å‚³åˆä½µå¾Œè³‡æ–™è¡¨
    return pd.concat(dfs, ignore_index=True) if dfs else pd.DataFrame()


# è‡ªå‹•æ›´æ–° fallback æª”æ¡ˆ(æ ¹æ“šå¿«å–æª”æ¡ˆç‹€æ…‹ï¼Œæ›´æ–°å€‹è‚¡è³‡æ–™æª”ï¼Œåªè£œæŠ“å°šæœªæœ‰çš„å€é–“)
def update_stock_data_incrementally(stock_code, stock_name, listed_date, fallback_dir="."):
    if pd.isna(listed_date):
        print(f"âš ï¸ {stock_code} ä¸Šå¸‚æ—¥æ ¼å¼éŒ¯èª¤ï¼Œç„¡æ³•è™•ç†")
        return

    fallback_path = os.path.join(fallback_dir, f"fallback_{stock_code}.csv")

    # å¿«å–æª”æ¡ˆåˆ¤æ–·èˆ‡è¨­å®šèµ·å§‹æ—¥
    if os.path.exists(fallback_path):
        df_old = pd.read_csv(fallback_path, encoding="utf-8-sig", parse_dates=["æ—¥æœŸ"])
        last_date = df_old["æ—¥æœŸ"].max().date()
        print(f"ğŸ“„ {stock_code} å·²æœ‰è³‡æ–™ï¼Œæœ€å¾Œæ—¥æœŸï¼š{last_date}")
        start = last_date + timedelta(days=1)
    else:
        df_old = pd.DataFrame()
        start = listed_date.date()
        print(f"ğŸ†• å»ºç«‹ {stock_code} æ–°è³‡æ–™æª”ï¼Œå¾ {start} é–‹å§‹")

    today = date.today()

    # è‹¥å·²æ›´æ–°å‰‡ç•¥é
    if start > today:
        print(f"âœ… {stock_code} è³‡æ–™å·²ç‚ºæœ€æ–°ï¼Œç•¥éæ›´æ–°")
        return

    df_new = get_tw_stock_data(start, today, stock_code, listed_date)
    if df_new.empty:
        print(f"âš ï¸ {stock_code} æ²’æœ‰æŠ“åˆ°æ–°è³‡æ–™")
        return

    # åˆä½µæ–°èˆŠè³‡æ–™ä¸¦å„²å­˜
    df_new.insert(1, "æœ‰åƒ¹è­‰åˆ¸ä»£è™Ÿåç¨±", stock_name)
    df_final = pd.concat([df_old, df_new], ignore_index=True).drop_duplicates(subset=["æ—¥æœŸ"])
    df_final = df_final.sort_values(by="æ—¥æœŸ")
    df_final.to_csv(fallback_path, index=False, encoding="utf-8-sig")
    print(f"âœ… {stock_code} æ›´æ–°å®Œæˆï¼Œå…± {len(df_final)} ç­†")


# æª¢æŸ¥ fallback CSV ç‹€æ…‹(æ˜¯å¦å­˜åœ¨ã€æ ¼å¼æ­£ç¢º?)ï¼Œä¸¦å›å‚³æœ‰æ•ˆåå–®èˆ‡æ‘˜è¦è¡¨
def check_fallback_csvs(stock_codes, fallback_dir="."):
    results = []

    for code in stock_codes:
        path = os.path.join(fallback_dir, f"fallback_{code}.csv")
        # æª”æ¡ˆå­˜åœ¨æ€§èˆ‡è³‡æ–™ç­†æ•¸æª¢æŸ¥
        if not os.path.exists(path):
            print(f"ğŸ“› ç¼ºå°‘ fallback_{code}.csv")
            results.append({"è‚¡ç¥¨ä»£è™Ÿ": code, "ç‹€æ…‹": "âŒ æª”æ¡ˆä¸å­˜åœ¨", "ç­†æ•¸": 0})
            continue

        try:
            df = pd.read_csv(path, parse_dates=["æ—¥æœŸ"])
            count = len(df.dropna(subset=["æ”¶ç›¤åƒ¹", "æˆäº¤è‚¡æ•¸"]))
            if count < 10:
                results.append({"è‚¡ç¥¨ä»£è™Ÿ": code, "ç‹€æ…‹": f"âš ï¸ è³‡æ–™éå°‘ï¼ˆ{count} ç­†ï¼‰", "ç­†æ•¸": count})
            else:
                results.append({"è‚¡ç¥¨ä»£è™Ÿ": code, "ç‹€æ…‹": "âœ… æœ‰æ•ˆ", "ç­†æ•¸": count})
        except Exception as e:
            results.append({"è‚¡ç¥¨ä»£è™Ÿ": code, "ç‹€æ…‹": f"âŒ è®€å–éŒ¯èª¤: {e}", "ç­†æ•¸": 0})

    df_result = pd.DataFrame(results)
    valid_codes = df_result[df_result["ç‹€æ…‹"] == "âœ… æœ‰æ•ˆ"]["è‚¡ç¥¨ä»£è™Ÿ"].tolist()

    # å›å‚³æœ‰æ•ˆä»£ç¢¼èˆ‡å ±å‘Šè¡¨æ ¼
    return valid_codes, df_result


# æŒ‡å®šé è¨­è¦æŠ“å–èˆ‡è™•ç†çš„è‚¡ç¥¨ä»£è™Ÿæ¸…å–®(å¾ŒçºŒæ•´åˆGUIä»‹é¢ï¼Œè®“ä½¿ç”¨è€…è¼¸å…¥æŒ‡å®š)
def get_target_codes():
    return ['2330', '2454', '1590', '6669']
